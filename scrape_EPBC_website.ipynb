{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the Python modules necessary for this notebook to run. These can be installed using, for instance, `pip` or `conda`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T03:51:01.602829Z",
     "start_time": "2021-06-07T03:51:01.081827Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # Handles maths\n",
    "import pandas as pd # Good for tables of data\n",
    "import matplotlib.pyplot as plt # Handles graphing\n",
    "import requests # Downloads webpages\n",
    "from bs4 import BeautifulSoup # For parsing webpages\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os, sys\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T03:51:01.605760Z",
     "start_time": "2021-06-07T03:51:01.604047Z"
    }
   },
   "outputs": [],
   "source": [
    "# stored_table = pd.read_csv('/home/student.unimelb.edu.au/shorte1/Documents/ACF_consulting/EPBC_notices_test.csv')\n",
    "# stored_table[stored_table['Reference Number'] == '2019/8527']\n",
    "# stored_table = stored_table.drop(1539, axis=0).reset_index(drop=True)\n",
    "# stored_table.to_csv('/home/student.unimelb.edu.au/shorte1/Documents/ACF_consulting/EPBC_notices_test.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T03:51:01.925643Z",
     "start_time": "2021-06-07T03:51:01.918303Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"http://epbcnotices.environment.gov.au/publicnoticesreferrals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T03:51:09.221893Z",
     "start_time": "2021-06-07T03:51:02.346056Z"
    }
   },
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless') # Comment out to see the actions on website\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument(\"--start-maximized\")\n",
    "\n",
    "base_dir = '/home/student.unimelb.edu.au/shorte1/Documents/ACF_consulting/' \n",
    "sub_dir = 'files_test'\n",
    "files_dir = base_dir + sub_dir \n",
    "\n",
    "options.add_experimental_option(\"prefs\", {\n",
    "  \"download.default_directory\": files_dir,\n",
    "  \"download.prompt_for_download\": False,\n",
    "  \"download.directory_upgrade\": True,\n",
    "  \"safebrowsing.enabled\": True,\n",
    "  \"plugins.always_open_pdf_externally\": True\n",
    "})\n",
    "\n",
    "driver = webdriver.Chrome('/usr/bin/chromedriver', options=options)\n",
    "driver.get(url);\n",
    "time.sleep(4)\n",
    "\n",
    "def clean_columns(table):\n",
    "    name_dict = {}\n",
    "    clean_str = '  . Activate to sort in descending order'\n",
    "    for col in range(len(table.columns)): \n",
    "        name_dict[table.columns[col]] = table.columns[col].replace(clean_str, '')\n",
    "    return table.rename(name_dict, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Page Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T03:51:09.268236Z",
     "start_time": "2021-06-07T03:51:09.229382Z"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_page(\n",
    "        driver, page_number, table, stored_table, \n",
    "        exist, update_mode=False):\n",
    "    \n",
    "    # Two modes - download or update mode.\n",
    "    # If in download mode, search forward, skipping files that already exist \n",
    "    # in table.\n",
    "    # If in update mode, search forward, but assume new entries to website\n",
    "    # appear first, so stop when a certain number of matches have occured. \n",
    "\n",
    "    xpath = '//a[@class=\"btn btn-default btn-xs\" '\n",
    "    xpath += 'and @href=\"#\" and @data-toggle=\"dropdown\"]'\n",
    "    details_buttons = driver.find_elements_by_xpath(xpath)\n",
    "\n",
    "    xpath = '//a[@class=\"details-link launch-modal\" '\n",
    "    xpath += 'and @href=\"#\" and @title=\"View Details\"]'\n",
    "    details_links = driver.find_elements_by_xpath(xpath)\n",
    "    \n",
    "    try:\n",
    "        next_button = driver.find_elements_by_xpath(\n",
    "            '//a[@href=\"#\" and @data-page=\"' + str(page_number+1) + '\"]'\n",
    "        )[1]\n",
    "    except:\n",
    "        print('Last page reached.')\n",
    "        next_button = driver.find_elements_by_xpath(\n",
    "            '//a[@href=\"#\" and @data-page=\"' + str(page_number) + '\"]'\n",
    "        )[0]\n",
    "\n",
    "    # These will record the number of files and filenames for each submission\n",
    "    num_files = []\n",
    "    file_names = []\n",
    "\n",
    "    # Iterate over the 30 entries in the table on current page checking for files\n",
    "    for i in range(30):\n",
    "\n",
    "        # If already downloaded, skip this row\n",
    "        if exist[i]:\n",
    "            continue\n",
    "\n",
    "        if i < 29: \n",
    "            # Move to element i+1, as i may be blocked by Chrome download bar! \n",
    "            ActionChains(driver).move_to_element(details_buttons[i+1]).perform()\n",
    "            details_buttons[i].click()\n",
    "            time.sleep(.5)\n",
    "        else:\n",
    "            # Move to navigation bar, as i may be blocked by Chrome download bar!\n",
    "            ActionChains(driver).move_to_element(next_button).perform()\n",
    "            details_buttons[i].click()\n",
    "            time.sleep(.5)\n",
    "\n",
    "        ActionChains(driver).move_to_element(details_links[i]).perform()\n",
    "        details_links[i].click()\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        iframe = driver.find_elements_by_xpath(\n",
    "            '//section[@class=\"modal fade modal-form modal-form-details in\"]'\n",
    "            + '/div/div/div/iframe'\n",
    "        )\n",
    "        driver.switch_to.frame(iframe[0])\n",
    "\n",
    "        file_links = driver.find_elements_by_xpath(\n",
    "            \"//a[contains(@href, '/_entity/annotation/')]\"\n",
    "        )\n",
    "        \n",
    "        if len(file_links) >= 17:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        # NOTE need to check if bash shells exist on windows 10.\n",
    "        subprocess.run('rm ' + files_dir +'/*.pdf', shell=True)\n",
    "        ref_num = table['Reference Number'].iloc[i].replace('/','')\n",
    "        date = table['Date of notice'].iloc[i].strftime('%d%m%Y')\n",
    "        org = table['Title of referral'].iloc[i].split('/')[0]\n",
    "        org = org.translate(str.maketrans('', '', string.punctuation))\n",
    "        org = org.replace(' ', '_')\n",
    "        ref_type = table['Notification from EPBC Act'].iloc[i]\n",
    "        ref_type = ref_type.translate(\n",
    "            str.maketrans('', '', string.punctuation))\n",
    "        ref_type = ref_type.replace(' ', '_')\n",
    "        \n",
    "        # If no file links, don't try to download    \n",
    "        if not file_links:\n",
    "            num_files.append(0)\n",
    "            file_names.append('')\n",
    "            table.at[i, 'Attachments'] = 'No'\n",
    "            table.at[i, 'Download'] = 'NA'\n",
    "            table.at[i, 'Download Folder'] = 'NA'\n",
    "        # If file links, try to download\n",
    "        else:\n",
    "            table.at[i, 'Attachments'] = 'Yes'\n",
    "            num_files.append(len(file_links))\n",
    "\n",
    "            # Check if folder name already exists, if so append count\n",
    "            folder_name = ref_num + '_' + date + '_' + org + '_' + ref_type\n",
    "            folder_name = folder_name.lower()\n",
    "            shell_cmd = 'find ' + files_dir + '/*' + folder_name + '* -maxdepth 1 '\n",
    "            shell_cmd += '-type d | wc -l > ' + files_dir + '/folder_count.txt'\n",
    "            subprocess.run(shell_cmd, shell=True)\n",
    "            table.at[i, 'Download Folder'] = folder_name\n",
    "            try:\n",
    "                folder_count = int(np.loadtxt(files_dir + '/folder_count.txt'))\n",
    "            except:\n",
    "                folder_count = 0\n",
    "            subprocess.run('rm ' + files_dir + '/folder_count.txt', shell=True)\n",
    "            # Remove duplicate links - otherwise download code below breaks\n",
    "            # when the same file downloads and overwrites itself, resulting\n",
    "            # in file_count == len(file_links) never being satisfied\n",
    "            unique_file_links = []\n",
    "            unique_file_links_html = []\n",
    "            file_links_html = set([x.get_attribute('innerHTML') for x in file_links])\n",
    "            for k in range(len(file_links)):\n",
    "                link_text = file_links[k].get_attribute('innerHTML')\n",
    "                if re.search('.pdf', link_text, re.IGNORECASE):\n",
    "                    if file_links[k].get_attribute('innerHTML') not in unique_file_links_html:\n",
    "                        unique_file_links.append(file_links[k])\n",
    "                        unique_file_links_html.append(\n",
    "                            file_links[k].get_attribute('innerHTML')\n",
    "                        )\n",
    "                else:\n",
    "                    print('Non pdf files found on page ' + str(page_number) \n",
    "                          + ', row ' + str(i+1) \n",
    "                          + '. Check manually.')\n",
    "            file_links = unique_file_links\n",
    "                                \n",
    "#             if folder_count > 0:\n",
    "#                 if folder_count == 1:\n",
    "#                     # Append '_1' to existing folder\n",
    "#                     shell_cmd = 'mv ' + files_dir + \"/\" + folder_name + ' '\n",
    "#                     shell_cmd += files_dir + \"/\" + folder_name + '_1'\n",
    "#                     subprocess.run(shell_cmd, shell=True)\n",
    "#                 # Appead folder_count + 1 to new folder\n",
    "#                 folder_name += '_' + str(folder_count+1)\n",
    "            folder_path = files_dir + '/' + folder_name\n",
    "\n",
    "            successful = False\n",
    "            attempts = 0\n",
    "            table.at[i, 'Download'] = 'Success'\n",
    "            while not successful:\n",
    "                if attempts > 0:\n",
    "                    print('Download on page ' + str(page_number) \n",
    "                          + ', row ' + str(i+1) \n",
    "                          + ' timed out too many times.')\n",
    "                    table.at[i, 'Download'] = 'Fail'\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    for j in range(len(file_links)):\n",
    "                        file_links[j].click()\n",
    "                        time.sleep(0.25)\n",
    "\n",
    "                    # Wait for files to download\n",
    "                    file_count = 0\n",
    "                    iterations = 0\n",
    "                    while file_count < len(file_links):\n",
    "                        if iterations > 1200:\n",
    "                            attempts += 1\n",
    "                            raise RuntimeError('Download timed out.')\n",
    "                        time.sleep(1)\n",
    "                        shell_cmd = '''find ''' + files_dir + '/*.PDF '\n",
    "                        shell_cmd += '''-maxdepth 1 -exec sh -c 'mv \"$1\" \"${1%.PDF}.pdf\"' _ {} \\;'''\n",
    "                        subprocess.run(shell_cmd, shell=True)\n",
    "                        shell_cmd = 'find ' + files_dir + '/*.pdf '\n",
    "                        shell_cmd += '-type f -print | wc -l > ' \n",
    "                        shell_cmd += files_dir + '/num_files.txt'\n",
    "                        subprocess.run(shell_cmd, shell=True)\n",
    "                        file_count = int(np.loadtxt(\n",
    "                            files_dir + '/num_files.txt'))\n",
    "                        iterations += 1\n",
    "                        time.sleep(.5)\n",
    "                        print('Still Downloading. Please Wait.')\n",
    "                    subprocess.run('rm ' + files_dir + '/num_files.txt', shell=True)\n",
    "                    successful = True\n",
    "                    time.sleep(1)\n",
    "                except:\n",
    "                    attempts += 1\n",
    "                    time.sleep(1)\n",
    "                    print('Download failed.')\n",
    "\n",
    "            # After files downloaded, move them to appropriate folder\n",
    "            subprocess.run(['mkdir', folder_path])\n",
    "            shell_cmd = 'mv ' + files_dir + '/*.pdf ' + folder_path \n",
    "            subprocess.run(shell_cmd, shell=True)\n",
    "\n",
    "            # Record the filenames\n",
    "            shell_cmd = 'find ' + folder_path + '/*.pdf -maxdepth 1 -type f '\n",
    "            shell_cmd += '-printf \"%f\\n\" > ' + folder_path + '/file_names.txt'\n",
    "            subprocess.run(shell_cmd, shell=True)\n",
    "            with open(folder_path + '/file_names.txt') as f:\n",
    "                lines = f.readlines()\n",
    "            file_names.append(', '.join(lines).replace('\\n',''))\n",
    "            subprocess.run('rm ' + folder_path + '/file_names.txt', shell=True)\n",
    "\n",
    "            shell_cmd = 'pdfunite ' + folder_path + '/*.pdf ' + folder_path \n",
    "            shell_cmd += '/' + folder_name + '_combined.pdf'\n",
    "            subprocess.run(shell_cmd, shell=True)\n",
    "    \n",
    "        driver.switch_to.default_content()\n",
    "        xpath = '//section[@class=\"modal fade modal-form '\n",
    "        xpath += 'modal-form-details in\"]/div/div/div/button'\n",
    "        close_button = driver.find_elements_by_xpath(xpath)\n",
    "        close_button[0].click()\n",
    "        time.sleep(.5)\n",
    "        \n",
    "        # Append the downloaded row to the stored table and save\n",
    "        row = table.iloc[i]\n",
    "        stored_table = stored_table.append(row, ignore_index=True)\n",
    "        stored_table = stored_table.sort_values(\n",
    "            by='Date of notice', axis = 0, \n",
    "            ascending=False\n",
    "        )\n",
    "        stored_table = stored_table.reset_index(drop=True)\n",
    "        stored_table['Date of notice'] = stored_table['Date of notice'].apply(\n",
    "            lambda x: x.strftime('%d/%m/%Y'))\n",
    "        stored_table.to_csv('/home/student.unimelb.edu.au/shorte1/Documents/ACF_consulting/EPBC_notices_test.csv', index=False, header=True)\n",
    "        stored_table['Date of notice'] = pd.to_datetime(stored_table['Date of notice'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T03:51:09.280118Z",
     "start_time": "2021-06-07T03:51:09.273571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-07T03:51:10.345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "> \u001b[0;32m<ipython-input-5-096fe0084f9e>\u001b[0m(69)\u001b[0;36mscrape_page\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m        \u001b[0;31m# NOTE need to check if bash shells exist on windows 10.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m        \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfiles_dir\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/*.pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m        \u001b[0mref_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Reference Number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m        \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date of notice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d%m%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "Still Downloading. Please Wait.\n",
      "> \u001b[0;32m<ipython-input-5-096fe0084f9e>\u001b[0m(69)\u001b[0;36mscrape_page\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m        \u001b[0;31m# NOTE need to check if bash shells exist on windows 10.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m        \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfiles_dir\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/*.pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m        \u001b[0mref_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Reference Number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m        \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date of notice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d%m%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    \n",
    "    loading = True\n",
    "    attempts = 0\n",
    "    while loading:\n",
    "        if attempts > 30:\n",
    "            raise RuntimeError('Could not load website')\n",
    "        try:\n",
    "            time.sleep(2)\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source)\n",
    "            table = pd.read_html(soup.prettify())[0]\n",
    "            if len(table) == 30:\n",
    "                loading = False\n",
    "        except:\n",
    "            attempts += 1\n",
    "\n",
    "    table = clean_columns(table)\n",
    "    table['Attachments'] = ['TBD']*30\n",
    "    table['Download'] = ['TBD']*30\n",
    "    table['Download Folder'] = ['TBD']*30    \n",
    "    table['Date of notice'] = pd.to_datetime(\n",
    "        table['Date of notice'], dayfirst=True)\n",
    "    table.drop(labels='Actions', axis=1, inplace=True)  \n",
    "    \n",
    "    try:\n",
    "        stored_table = pd.read_csv(base_dir + '/EPBC_notices_test.csv')\n",
    "        stored_table['Date of notice'] = pd.to_datetime(\n",
    "            stored_table['Date of notice'], dayfirst=True)\n",
    "        shared = pd.merge(table, stored_table, how='left', indicator='Exist')\n",
    "        shared['Exist'] = np.where(shared.Exist == 'both', True, False)\n",
    "        exist = shared['Exist']\n",
    "        del shared\n",
    "    except:\n",
    "        stored_table = table.iloc[0:0]\n",
    "        stored_table['Date of notice'] = pd.to_datetime(\n",
    "            stored_table['Date of notice'], dayfirst=True)\n",
    "        exist = [False]*30\n",
    "        exist = pd.Series(exist,name='Exist')\n",
    "     \n",
    "    if np.any(~exist):\n",
    "        scrape_page(driver, i, table, stored_table, exist)\n",
    "    \n",
    "    try:\n",
    "        next_button = driver.find_elements_by_xpath(\n",
    "            '//a[@href=\"#\" and @data-page=\"' + str(i+1) + '\"]'\n",
    "        )[1]\n",
    "        ActionChains(driver).move_to_element(next_button).perform()\n",
    "        next_button.click()\n",
    "    except:\n",
    "        print('Quitting.')\n",
    "    \n",
    "    del table, stored_table\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
