{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the Python modules necessary for this notebook to run. These can be installed using, for instance, `pip` or `conda`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T06:17:59.973632Z",
     "start_time": "2021-03-05T06:17:59.216006Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # Handles maths\n",
    "import pandas as pd # Good for tables of data\n",
    "import matplotlib.pyplot as plt # Handles graphing\n",
    "import xarray as xr # Helpful for spatial data\n",
    "import requests # Downloads webpages\n",
    "from bs4 import BeautifulSoup # For parsing webpages\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os, sys\n",
    "import time\n",
    "import subprocess\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T06:17:59.977397Z",
     "start_time": "2021-03-05T06:17:59.975109Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"http://epbcnotices.environment.gov.au/publicnoticesreferrals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T06:18:04.681403Z",
     "start_time": "2021-03-05T06:18:00.168160Z"
    }
   },
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless') # Comment out to see the actions on website\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument(\"--start-maximized\")\n",
    "\n",
    "base_dir = '/home/student.unimelb.edu.au/shorte1/Documents/ACF_consulting/files'\n",
    "\n",
    "options.add_experimental_option(\"prefs\", {\n",
    "  \"download.default_directory\": base_dir,\n",
    "  \"download.prompt_for_download\": False,\n",
    "  \"download.directory_upgrade\": True,\n",
    "  \"safebrowsing.enabled\": True,\n",
    "  \"plugins.always_open_pdf_externally\": True\n",
    "})\n",
    "\n",
    "driver = webdriver.Chrome('/usr/bin/chromedriver', options=options)\n",
    "driver.get(url);\n",
    "time.sleep(1)\n",
    "\n",
    "loading = True\n",
    "while loading:\n",
    "    try:\n",
    "        time.sleep(0.5)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source)\n",
    "        \n",
    "        xpath = '//a[@class=\"btn btn-default btn-xs\" '\n",
    "        xpath += 'and @href=\"#\" and @data-toggle=\"dropdown\"]'\n",
    "        details_buttons = driver.find_elements_by_xpath(xpath)\n",
    "\n",
    "        xpath = '//a[@class=\"details-link launch-modal\" '\n",
    "        xpath += 'and @href=\"#\" and @title=\"View Details\"]'\n",
    "        details_links = driver.find_elements_by_xpath(xpath)\n",
    "\n",
    "        loading = False\n",
    "    except:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "table = pd.read_html(soup.prettify())[0]\n",
    "\n",
    "def clean_columns(table):\n",
    "    name_dict = {}\n",
    "    clean_str = '  . Activate to sort in descending order'\n",
    "    for col in range(len(table.columns)): \n",
    "        name_dict[table.columns[col]] = table.columns[col].replace(clean_str, '')\n",
    "    return table.rename(name_dict, axis='columns')\n",
    "    \n",
    "table = clean_columns(table)\n",
    "table.drop(labels='Actions', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T06:32:39.179358Z",
     "start_time": "2021-03-05T06:32:39.174248Z"
    }
   },
   "outputs": [],
   "source": [
    "table['Reference Number'].loc[0] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T06:32:44.957090Z",
     "start_time": "2021-03-05T06:32:44.938193Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    stored_table = pd.read_csv('/home/student.unimelb.edu.au/shorte1/Documents/ACF_consulting/EPBC_notices.csv')\n",
    "    shared = pd.merge(table, stored_table, how='left', indicator='Exist')\n",
    "    shared['Exist'] = np.where(shared.Exist == 'both', True, False)\n",
    "    exist = shared['Exist']\n",
    "    shared\n",
    "except:\n",
    "    shared=[False]*30\n",
    "    shared=pd.DataFrame(shared,columns=['Exist'])\n",
    "    exist=shared['Exist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T06:33:04.261502Z",
     "start_time": "2021-03-05T06:33:04.242316Z"
    }
   },
   "outputs": [],
   "source": [
    "shared.drop(labels='Exist', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T06:38:50.062061Z",
     "start_time": "2021-03-05T06:38:50.048208Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sort_values() got an unexpected keyword argument 'ignore_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ec18707bfdfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstored_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mexist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date of notice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sort_values() got an unexpected keyword argument 'ignore_index'"
     ]
    }
   ],
   "source": [
    "stored_table.append(shared[~exist], ignore_index=True).sort_values('Date of notice', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T06:11:37.479949Z",
     "start_time": "2021-03-05T06:11:37.440574Z"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_page(driver, page_number, table, exist):\n",
    "    \n",
    "    # Two modes - download or update mode.\n",
    "    # If in download mode, search forward, skipping files that already exist \n",
    "    # in table.\n",
    "    # If in update mode, search forward, but assume new entries to website\n",
    "    # appear first, so stop when a certain number of matches have occured. \n",
    "\n",
    "    xpath = '//a[@class=\"btn btn-default btn-xs\" '\n",
    "    xpath += 'and @href=\"#\" and @data-toggle=\"dropdown\"]'\n",
    "    details_buttons = driver.find_elements_by_xpath(xpath)\n",
    "\n",
    "    xpath = '//a[@class=\"details-link launch-modal\" '\n",
    "    xpath += 'and @href=\"#\" and @title=\"View Details\"]'\n",
    "    details_links = driver.find_elements_by_xpath(xpath)\n",
    "\n",
    "    next_button = driver.find_elements_by_xpath(\n",
    "        '//a[@href=\"#\" and @data-page=\"' + str(page_number+1) + '\"]'\n",
    "    )[1]\n",
    "\n",
    "    # These will record the number of files and filenames for each submission\n",
    "    num_files = []\n",
    "    file_names = []\n",
    "\n",
    "    # Iterate over the 30 entries in the table on current page checking for files\n",
    "    for i in range(30):\n",
    "\n",
    "        # If already downloaded, skip this row\n",
    "        if exist[i]:\n",
    "            continue\n",
    "\n",
    "        if i < 29: \n",
    "            # Move to element i+1, as i may be blocked by Chrome download bar! \n",
    "            ActionChains(driver).move_to_element(details_buttons[i+1]).perform()\n",
    "            details_buttons[i].click()\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            # Move to navigation bar, as i may be blocked by Chrome download bar!\n",
    "            ActionChains(driver).move_to_element(next_button).perform()\n",
    "            details_buttons[i].click()\n",
    "            time.sleep(1)\n",
    "\n",
    "        ActionChains(driver).move_to_element(details_links[i]).perform()\n",
    "        details_links[i].click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        iframe = driver.find_elements_by_xpath(\n",
    "            '//section[@class=\"modal fade modal-form modal-form-details in\"]'\n",
    "            + '/div/div/div/iframe'\n",
    "        )\n",
    "        driver.switch_to.frame(iframe[0])\n",
    "\n",
    "        file_links = driver.find_elements_by_xpath(\n",
    "            \"//a[contains(@href, '/_entity/annotation/')]\"\n",
    "        )\n",
    "\n",
    "        subprocess.run('rm ' + base_dir +'/*.pdf', shell=True)\n",
    "        ref_num = table['Reference Number'].iloc[i].replace('/','')\n",
    "        date = table['Date of notice'].iloc[i]\n",
    "        date = re.sub(r'(^\\d\\/)',r'0\\1',date)\n",
    "        date = date.replace('/','')\n",
    "\n",
    "        # If no files, skip this entry    \n",
    "        if not file_links:\n",
    "            num_files.append(0)\n",
    "            file_names.append('')\n",
    "\n",
    "            driver.switch_to.default_content()\n",
    "            xpath = '//section[@class=\"modal fade modal-form '\n",
    "            xpath += 'modal-form-details in\"]/div/div/div/button'\n",
    "            close_button = driver.find_elements_by_xpath(xpath)\n",
    "            close_button[0].click()\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        num_files.append(len(file_links))\n",
    "\n",
    "        # Check if folder name already exists, if so append count\n",
    "        folder_name = ref_num + '_' + date\n",
    "        shell_cmd = 'find ' + base_dir + '/*' + folder_name + '* -maxdepth 1 '\n",
    "        shell_cmd += '-type d | wc -l > ' + base_dir + '/folder_count.txt'\n",
    "        subprocess.run(shell_cmd, shell=True)\n",
    "        folder_count = int(np.loadtxt(base_dir + '/folder_count.txt'))\n",
    "        subprocess.run('rm ' + base_dir + '/folder_count.txt', shell=True)\n",
    "\n",
    "        if folder_count > 0:\n",
    "            if folder_count == 1:\n",
    "                # Append '_1' to existing folder\n",
    "                shell_cmd = 'mv ' + base_dir + \"/\" + folder_name + ' '\n",
    "                shell_cmd += base_dir + \"/\" + folder_name + '_1'\n",
    "                subprocess.run(shell_cmd, shell=True)\n",
    "            # Appead folder_count + 1 to new folder\n",
    "            folder_name += '_' + str(folder_count+1)\n",
    "        folder_path = base_dir + '/' + folder_name\n",
    "\n",
    "        for j in range(len(file_links)):\n",
    "            file_links[j].click()\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        # Wait for files to download\n",
    "        file_count = 0\n",
    "        iterations = 0\n",
    "        while file_count < len(file_links):\n",
    "            if iterations > 1800:\n",
    "                raise RuntimeError('Download timed out.')\n",
    "            time.sleep(.5)\n",
    "            shell_cmd = 'find ' + base_dir + '/*.pdf '\n",
    "            shell_cmd += '-type f -print | wc -l > ' \n",
    "            shell_cmd += base_dir + '/num_files.txt'\n",
    "            subprocess.run(shell_cmd, shell=True)\n",
    "            file_count = int(np.loadtxt(base_dir + '/num_files.txt'))\n",
    "            iterations += 1\n",
    "        subprocess.run('rm ' + base_dir + '/num_files.txt', shell=True)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # After files downloaded, move them to appropriate folder\n",
    "        subprocess.run(['rm', '-r', folder_path])\n",
    "        subprocess.run(['mkdir', folder_path])\n",
    "        shell_cmd = 'mv ' + base_dir + '/*.pdf ' + folder_path \n",
    "        subprocess.run(shell_cmd, shell=True)\n",
    "\n",
    "        # Record the filenames\n",
    "        shell_cmd = 'find ' + folder_path + '/*.pdf -maxdepth 1 -type f '\n",
    "        shell_cmd += '-printf \"%f\\n\" > ' + folder_path + '/file_names.txt'\n",
    "        subprocess.run(shell_cmd, shell=True)\n",
    "        with open(folder_path + '/file_names.txt') as f:\n",
    "            lines = f.readlines()\n",
    "        file_names.append(', '.join(lines).replace('\\n',''))\n",
    "        subprocess.run('rm ' + folder_path + '/file_names.txt', shell=True)\n",
    "\n",
    "        shell_cmd = 'pdfunite ' + folder_path + '/*.pdf ' + folder_path \n",
    "        shell_cmd += '/' + folder_name + '_combined.pdf'\n",
    "        subprocess.run(shell_cmd, shell=True)\n",
    "\n",
    "        driver.switch_to.default_content()\n",
    "        xpath = '//section[@class=\"modal fade modal-form '\n",
    "        xpath += 'modal-form-details in\"]/div/div/div/button'\n",
    "        close_button = driver.find_elements_by_xpath(xpath)\n",
    "        close_button[0].click()\n",
    "        time.sleep(1)\n",
    "\n",
    "    table.to_csv('/home/student.unimelb.edu.au/shorte1/Documents/ACF_consulting/EPBC_notices.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T06:17:02.834311Z",
     "start_time": "2021-03-05T06:11:46.547030Z"
    }
   },
   "outputs": [],
   "source": [
    "scrape_page(driver, 1, table, shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-27T03:19:17.439331Z",
     "start_time": "2021-02-27T03:18:59.173400Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(2,3):\n",
    "\n",
    "    next_button = driver.find_elements_by_xpath(\n",
    "        '//a[@href=\"#\" and @data-page=\"' + str(i) + '\"]'\n",
    "    )[1]\n",
    "    next_button.click()\n",
    "    time.sleep(10+np.random.rand()*10-5)\n",
    "    page_source = driver.page_source\n",
    "    new_soup = BeautifulSoup(page_source)\n",
    "    new_table = pd.read_html(new_soup.prettify())[0]\n",
    "    new_table = clean_columns(new_table)\n",
    "    table = table.append(new_table, ignore_index=True)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
